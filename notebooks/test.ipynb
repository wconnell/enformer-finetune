{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -L https://github.com/lucidrains/enformer-pytorch/raw/main/data/test-sample.pt -o data/test-sample.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/home/wconnell/anaconda3/envs/eft/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from enformer_pytorch import Enformer, GenomeIntervalDataset\n",
    "\n",
    "import kipoiseq\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on MPS: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Running on MPS:\", device)\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Running on GPU:\", device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on CPU:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_MODEL = False\n",
    "\n",
    "if TEST_MODEL:\n",
    "    enformer = Enformer.from_pretrained('EleutherAI/enformer-official-rough').to(device)\n",
    "    data = torch.load('../data/test-sample.pt', map_location=device)\n",
    "    seq, target = data['sequence'].to(device), data['target'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        corr_coef = enformer(\n",
    "            seq,\n",
    "            target = target,\n",
    "            return_corr_coef = True,\n",
    "            head = 'human'\n",
    "        )\n",
    "\n",
    "    print(corr_coef)\n",
    "    assert corr_coef > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def avg_bin(array, n_bins):\n",
    "    splitted = np.array_split(array, n_bins)\n",
    "    binned_array = [np.mean(a) for a in splitted]\n",
    "    return binned_array\n",
    "\n",
    "# Data\n",
    "seq_data = pd.read_pickle(\"../data/processed/PROMOTERS.pkl\")\n",
    "\n",
    "# Target\n",
    "target = seq_data['values']\n",
    "target = torch.stack([torch.tensor(i) for i in target]).unsqueeze(-1)\n",
    "\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 1 # T4 only enough memory for 1 batch size\n",
    "\n",
    "seq_ds = GenomeIntervalDataset(\n",
    "    bed_file = '../data/processed/PROMOTERS.bed',                       # bed file - columns 0, 1, 2 must be <chromosome>, <start position>, <end position>\n",
    "    fasta_file = '../data/hg38.fa',                        # path to fasta file\n",
    "    return_seq_indices = True,                          # return nucleotide indices (ACGTN) or one hot encodings\n",
    "    context_length = 196_608,\n",
    ")\n",
    "\n",
    "seq_dl = DataLoader(seq_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "target_ds = TensorDataset(target)\n",
    "target_dl = DataLoader(target_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enformer_pytorch import seq_indices_to_one_hot # is this only neccessary for CPU and MPS??\n",
    "from enformer_pytorch.finetune import HeadAdapterWrapper\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch\n",
    "\n",
    "# Training loop\n",
    "model_path = Path(\"../test-models/\")\n",
    "\n",
    "# Setup paths\n",
    "now = datetime.now()\n",
    "formatted_date_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "folder_path = model_path.joinpath(formatted_date_time)\n",
    "folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Model\n",
    "enformer = Enformer.from_pretrained('EleutherAI/enformer-official-rough')\n",
    "enformer = HeadAdapterWrapper(\n",
    "    enformer=enformer,\n",
    "    num_tracks=1,\n",
    "    post_transformer_embed=False\n",
    ").to(device)\n",
    "_ = enformer.train()\n",
    "\n",
    "scaler = GradScaler()\n",
    "optimizer = torch.optim.Adam(enformer.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 1\n",
    "accumulation_steps = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0  # Keep track of the running loss\n",
    "    for idx, (seq_batch, (target_batch,)) in enumerate(zip(seq_dl, target_dl)):\n",
    "        if device != 'cuda':\n",
    "            seq_batch = seq_indices_to_one_hot(seq_batch)\n",
    "        seq_batch = seq_batch.to(dtype=torch.float32, device=device)\n",
    "        target_batch = target_batch.to(dtype=torch.float32, device=device)\n",
    "        \n",
    "        with autocast():\n",
    "            # Forward pass\n",
    "            loss = enformer(seq_batch, target=target_batch)\n",
    "\n",
    "        # Backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (idx + 1) % accumulation_steps == 0:  # Update every accumulation_steps\n",
    "            # Gradient accumulation\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    avg_loss = running_loss / len(seq_dl)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{idx+1}/{len(seq_dl)}], Avg Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save model (optional)\n",
    "    model_path = folder_path.joinpath(f'enformer-ft_epoch={epoch}_loss={avg_loss:.4f}.pth')\n",
    "    torch.save(enformer.state_dict(), model_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eft.data import CustomGenomeIntervalDataset\n",
    "from eft.models import EnformerTX\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data/sequences')\n",
    "ckpt_path = \"../lightning_logs/90-10/version_2/checkpoints/epoch=3-step=1116.ckpt\"\n",
    "batch_size = 4\n",
    "\n",
    "val = CustomGenomeIntervalDataset(\n",
    "    bed_file = data_dir.joinpath('val.bed'),\n",
    "    fasta_file = '../data/hg38.fa',\n",
    "    return_seq_indices = True,\n",
    "    context_length = 196_608,\n",
    ")\n",
    "val_dl = DataLoader(val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "enformer = EnformerTX.load_from_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_rand = False\n",
    "\n",
    "_ = enformer.eval()\n",
    "\n",
    "all_target = []\n",
    "all_pred = []\n",
    "corr_coefs = []\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "with torch.no_grad():\n",
    "  for epoch in range(num_epochs):\n",
    "      for idx, batch in enumerate(val_dl):\n",
    "          seq, target = batch\n",
    "          \n",
    "          # filter out random seq with 0 expression\n",
    "          if filter_rand:\n",
    "            promoters = (target.sum(axis=1) != 0)\n",
    "            seq = seq[promoters]\n",
    "            target = target[promoters]\n",
    "\n",
    "          out = enformer(seq.to(enformer.device), None)\n",
    "          out = out.squeeze(-1).cpu().numpy()\n",
    "          target = target.cpu().numpy()\n",
    "          all_target.append(target)\n",
    "          all_pred.append(out)\n",
    "          # for i in range(len(target)):\n",
    "          #   rho, pval = pearsonr(target[i], out[i])\n",
    "          #   corr_coefs.append(rho)\n",
    "          if idx == 2: break\n",
    "\n",
    "all_target = np.concatenate(all_target)\n",
    "all_pred = np.concatenate(all_pred)\n",
    "# # viz\n",
    "# avg_cc = np.mean(corr_coefs)\n",
    "# sns.violinplot(corr_coefs)\n",
    "# sns.swarmplot(corr_coefs, color='k')\n",
    "# plt.title(f\"Average pearsonr={avg_cc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.02049967, 0.04243984, ..., 0.01965334, 0.05225051,\n",
       "        0.05141183],\n",
       "       [0.03897707, 0.05997542, 0.04063922, ..., 0.39189282, 0.27917278,\n",
       "        0.11266407],\n",
       "       [0.01102549, 0.08504591, 0.09557272, ..., 0.01599106, 0.01685769,\n",
       "        0.0076321 ],\n",
       "       ...,\n",
       "       [0.02227262, 0.00398912, 0.01756323, ..., 0.05750633, 0.05960308,\n",
       "        0.05663969],\n",
       "       [0.        , 0.00470938, 0.01711997, ..., 0.00089461, 0.00304725,\n",
       "        0.00053117],\n",
       "       [0.06579287, 0.05983687, 0.02326989, ..., 0.01822758, 0.        ,\n",
       "        0.0148728 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_target\n",
    "all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr22</td>\n",
       "      <td>15527192</td>\n",
       "      <td>15529192</td>\n",
       "      <td>promoter</td>\n",
       "      <td>[0.01468216348439455, 0.005263423758812926, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr12</td>\n",
       "      <td>27709822</td>\n",
       "      <td>27711822</td>\n",
       "      <td>promoter</td>\n",
       "      <td>[0.052080263807014984, 0.05263428305360404, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chrY</td>\n",
       "      <td>49339788</td>\n",
       "      <td>49438092</td>\n",
       "      <td>random</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chrY</td>\n",
       "      <td>49165093</td>\n",
       "      <td>49263397</td>\n",
       "      <td>random</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr22</td>\n",
       "      <td>14123836</td>\n",
       "      <td>14222140</td>\n",
       "      <td>random</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3  \\\n",
       "0  chr22  15527192  15529192  promoter   \n",
       "1  chr12  27709822  27711822  promoter   \n",
       "2   chrY  49339788  49438092    random   \n",
       "3   chrY  49165093  49263397    random   \n",
       "4  chr22  14123836  14222140    random   \n",
       "\n",
       "                                                   4  \n",
       "0  [0.01468216348439455, 0.005263423758812926, 0....  \n",
       "1  [0.052080263807014984, 0.05263428305360404, 0....  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## downsampel train/val\n",
    "train = pd.read_csv(\"../data/sequences/train_50-50.bed\", sep='\\t', header=None)\n",
    "val = pd.read_csv(\"../data/sequences/val_50-50.bed\", sep='\\t', header=None)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(dataset, label_column, positive_fraction):\n",
    "    \"\"\"\n",
    "    Balances the dataset based on the specified fraction of positive cases.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset (pd.DataFrame): The dataset to be balanced.\n",
    "    - label_column (int or str): The column in the dataset containing the class labels.\n",
    "    - positive_fraction (float): The desired fraction of positive cases in the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A balanced dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # Count the number of positive instances\n",
    "    pos_count = dataset[label_column].value_counts().loc['promoter']\n",
    "\n",
    "    # Calculate the number of negative instances needed for the desired balance\n",
    "    total_count = pos_count / positive_fraction\n",
    "    neg_count = int(total_count - pos_count)\n",
    "\n",
    "    # Extract positive and negative samples\n",
    "    positives = dataset[dataset[label_column] == 'promoter']\n",
    "    negatives = dataset[dataset[label_column] != 'promoter'].sample(n=neg_count)\n",
    "\n",
    "    # Concatenate and shuffle the dataset\n",
    "    balanced_dataset = pd.concat([positives, negatives]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return balanced_dataset\n",
    "\n",
    "# Example usage\n",
    "balanced_train = balance_dataset(train, 3, 0.9)\n",
    "balanced_val = balance_dataset(val, 3, 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_train.to_csv(\"../data/sequences/train.bed\", sep='\\t', header=None, index=False)\n",
    "balanced_val.to_csv(\"../data/sequences/val.bed\", sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
